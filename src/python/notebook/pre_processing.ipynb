{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda env create -f environment.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualization\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webscraping\n",
    "import glob\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import datetime\n",
    "from pandas.core.common import flatten\n",
    "import os\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing and pre-processing\n",
    "from glob import glob\n",
    "import os \n",
    "import re\n",
    "\n",
    "from pdfminer.high_level import extract_text\n",
    "import pdfplumber\n",
    "from langdetect import detect, DetectorFactory\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from string import punctuation\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector representations and embeddings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic and XGboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, precision_score, recall_score\n",
    "from xgboost import XGBClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\envs\\thesis\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# LSTM \n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT models\n",
    "from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(r\"../../../data/processed/data_merged_2023_02_01.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    5623\n",
       "fr       5\n",
       "de       4\n",
       "sv       2\n",
       "es       1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lang'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset English merger decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['lang']==\"en\"]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5623 entries, 0 to 5622\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   article   5623 non-null   object\n",
      " 1   case_num  5623 non-null   object\n",
      " 2   filename  5623 non-null   object\n",
      " 3   text      5623 non-null   object\n",
      " 4   lang      5623 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 219.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regular expression pattern\n",
    "pattern = r\"\\\\([^\\\\]*)$\"\n",
    "\n",
    "# apply regular expression to each row in \"filename\" column\n",
    "df['file'] = df['filename'].apply(lambda x: re.findall(pattern, x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='file', keep='first', inplace=True)\n",
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article'] = df['article'].replace('art6.1', 'article6(2)')\n",
    "df['article'] = df['article'].replace('art6.0', 'article6(1)(b)')\n",
    "df['article'] = df['article'].replace('art8.1', 'article8(1)')\n",
    "df['article'] = df['article'].replace('art8.2', 'article8(2)')\n",
    "df['article'] = df['article'].replace('art8.3', 'article8(3)')\n",
    "df['article'] = df['article'].replace('art9.3', 'referral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article\n",
       "article6(1)(b)    4831\n",
       "article6(2)        224\n",
       "article8(1)         36\n",
       "article8(2)         70\n",
       "article8(3)         11\n",
       "referral            24\n",
       "Name: case_num, dtype: int64"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no of cases by article\n",
    "df.groupby('article')['case_num'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article6(1)(b)    4899\n",
       "article6(2)        358\n",
       "article8(1)         47\n",
       "article8(2)        111\n",
       "article8(3)         14\n",
       "referral            29\n",
       "Name: article, dtype: int64"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no of documents by article\n",
    "df['article'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>filename</th>\n",
       "      <th>case_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>article6(2)</td>\n",
       "      <td>art6.1\\M.10431\\M_10431_8659694_2665_3</td>\n",
       "      <td>M.10431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>article6(2)</td>\n",
       "      <td>art6.1\\M.10431\\M_10431_8414584_2641_3</td>\n",
       "      <td>M.10431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          article                               filename case_num\n",
       "4986  article6(2)  art6.1\\M.10431\\M_10431_8659694_2665_3  M.10431\n",
       "4987  article6(2)  art6.1\\M.10431\\M_10431_8414584_2641_3  M.10431"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['case_num']==\"M.10431\"][['article', 'filename', 'case_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article6(1)(b)    4899\n",
       "article6(2)        358\n",
       "article8(1)         47\n",
       "article8(2)        111\n",
       "article8(3)         14\n",
       "referral            29\n",
       "Name: article, dtype: int64"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no of documents by article\n",
    "df['article'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nEUROPEAN COMMISSION \\nDG Competition \\n \\n \\n \\n \\n  Case  M.9004  -  SL04  / \\nAMBIENTA SGR / JV \\n \\n \\n \\n \\nOnly the English text is available and authentic. \\n \\n \\n \\nREGULATION (EC) No 139/2004 \\nMERGER PROCEDURE \\n \\n \\n \\nArticle 6(1)(b) NON-OPPOSITION \\nDate: 09/08/2018 \\n \\n \\n \\n \\n \\n \\n \\n \\nIn electronic form on the EUR-Lex website under document \\nnumber 32018M9004 \\n \\n \\n   \\nEUROPEAN COMMISSION \\n \\nBrussels, 09.08.2018 \\nC(2018) 5532 final \\nPUBLIC VERSION \\n \\n \\nTo the notifying parties \\n \\nSubject:  Case M.9004 – SL04/Ambienta Sgr/JV  \\nCommission decision pursuant to Article 6(1)(b) of Council Regulation (EC) \\n1 2\\nNo 139/2004  and Article 57 of the Agreement on the European Economic Area   \\nDear Sir or Madam, \\n1.  On  18  July  2018,  the  European  Commission  received  notification  of  a  proposed \\nconcentration pursuant to Article 4 of the Merger Regulation by which the undertakings \\nS.L.04  S.à.r.l.  (‘SL04’,  Luxembourg),  ultimately  controlled  by  L  Catterton  Partners \\n(‘L Catterton’, United States) and Ambienta Sgr S.p.A. (‘Ambienta’, Italy), ultimately \\ncontrolled by Ambienta Holding S.r.l. (Italy) acquire within the meaning of Article 3(1)(b) \\nand  3(4)  of  the  Merger  Regulation  joint  control  over  the  whole  of  the  undertaking \\nPibinew S.r.l. (‘Pibinew’, Italy) by way of a purchase of shares.3 \\n2.  The business activities of the undertakings concerned are: \\n\\uf02d  for SL04: a private equity firm indirectly controlled by L Catterton whose portfolio \\ncompanies  operate  in  the  retail  and  restaurant  business,  the  food  and  beverage \\nbusiness, consumer service and consumer product businesses including the production \\nand sale of cosmetics and fragrance products, \\n\\uf02d  for Ambienta: a private equity firm whose portfolio includes companies operating in \\nthe renewable power, biofuels, energy efficiency, pollution mitigation and waste and \\nwater resource management sectors, \\n                                                 \\n1  OJ L 24, 29.1.2004, p. 1 (the 'Merger Regulation'). With effect from 1 December 2009, the Treaty on the \\nFunctioning of the European Union ('TFEU') has introduced certain changes, such as the replacement of \\n'Community' by 'Union' and 'common market' by 'internal market'. The terminology of the TFEU will be used \\nthroughout this decision. \\n2   OJ L 1, 3.1.1994, p. 3 (the 'EEA Agreement'). \\n3   Publication in the Official Journal of the European Union No C 264, 26.7.2018, p. 17. \\n \\nCommission européenne, DG COMP MERGER REGISTRY, 1049 Bruxelles, BELGIQUE  \\nEuropese Commissie, DG COMP MERGER REGISTRY, 1049 Brussel,  BELGIË \\n \\n \\nTel: +32 229-91111. Fax: +32 229-64301. E-mail: COMP-MERGER-REGISTRY@ec.europa.eu.\\n   \\n\\uf02d  for Pibinew: designing, manufacturing, decorating and selling plastic packaging for \\nthe cosmetic industry. \\n3.  After examination of the notification, the European Commission has concluded that the \\nnotified operation falls within the scope of the Merger Regulation and of paragraph 5(c) of \\nthe Commission Notice on a simplified procedure for treatment of certain concentrations \\nunder Council Regulation (EC) No 139/2004.4 \\n4.  For the reasons set out in the Notice on a simplified procedure, the European Commission \\nhas decided not to oppose the notified operation and to declare it compatible with the \\ninternal market and with the EEA Agreement. This decision is adopted in application of \\nArticle 6(1)(b) of the Merger Regulation and Article 57 of the EEA Agreement. \\nFor the Commission \\n(Signed) \\nJohannes LAITENBERGER \\nDirector-General \\n \\n                                                 \\n4   OJ C 366, 14.12.2013, p. 5. \\n2 \""
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO: regex sections depending on article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_match(txt):\n",
    "    match = re.search(r\"(?i)article\\s*\\d+\\s*(\\([^\\)]+\\))?\\s*(\\([^\\)]+\\))?\", txt) \n",
    "    if match:\n",
    "        first_match = match.group()\n",
    "        return first_match.replace(\" \", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\").lower()\n",
    "    else:\n",
    "        return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "def article62(txt):\n",
    "    match = re.search(r\"(?i)IN\\s+CONJUNCTION\\s+WITH\\s+ART(?:ICLE)?\\s+\\d+\\(\\d+\\)\", txt)  \n",
    "    if match:\n",
    "        first_match = match.group()\n",
    "        return first_match.replace(\" \", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\").lower()\n",
    "    else:\n",
    "        return \"None\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article_txt'] = df['text'].apply(article_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article_txt'] = df['article_txt'].replace(\"article6(1)\", \"article6(2)\") # change to 6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article_62'] = df['text'].apply(article62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None                             5246\n",
       "inconjunctionwithart6(2)          154\n",
       "inconjunctionwitharticle6(2)       51\n",
       "inconjunctionwitharticle6(1)        2\n",
       "inconjunctionwitharticle22(3)       1\n",
       "inconjunctionwithart3(4)            1\n",
       "inconjunctionwitharticle3(4)        1\n",
       "inconjunctionwitharticle4(1)        1\n",
       "inconjunctionwitharticle18(4)       1\n",
       "Name: article_62, dtype: int64"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article_62'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article_txt'] = np.where(df['article_62'].isin(['inconjunctionwitharticle6(2)', 'inconjunctionwithart6(2)']), 'article6(2)', df['article_txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None                 1\n",
       "article11(1)         1\n",
       "article17(2)        99\n",
       "article21            1\n",
       "article22           12\n",
       "article22(1)         1\n",
       "article22(3)        42\n",
       "article232           1\n",
       "article4             1\n",
       "article4(4)         16\n",
       "article4(5)          1\n",
       "article57            2\n",
       "article6(1)(a)       1\n",
       "article6(1)(b)    4834\n",
       "article6(2)        257\n",
       "article6(4)          1\n",
       "article7(3)         32\n",
       "article8(1)         36\n",
       "article8(2)         75\n",
       "article8(3)         11\n",
       "article8(4)          1\n",
       "article9             3\n",
       "article9(2)          1\n",
       "article9(3)         26\n",
       "article9(3)(b)       2\n",
       "Name: article_txt, dtype: int64"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article_txt'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is referral if article == referral and not in 5 categories\n",
    "mask = (df['article_txt'].isin([\"article4(4)\", \"article22(3)\", \"article22\", \"article9(3)\", \"article9(3)(b)\"]))\n",
    "df.loc[mask, 'article_txt'] = \"referral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None                 1\n",
       "article11(1)         1\n",
       "article17(2)        99\n",
       "article21            1\n",
       "article22(1)         1\n",
       "article232           1\n",
       "article4             1\n",
       "article4(5)          1\n",
       "article57            2\n",
       "article6(1)(a)       1\n",
       "article6(1)(b)    4834\n",
       "article6(2)        257\n",
       "article6(4)          1\n",
       "article7(3)         32\n",
       "article8(1)         36\n",
       "article8(2)         75\n",
       "article8(3)         11\n",
       "article8(4)          1\n",
       "article9             3\n",
       "article9(2)          1\n",
       "referral            98\n",
       "Name: article_txt, dtype: int64"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article_txt'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - retain decision with commitments document same article_txt as the first tag of the case num\n",
    "# article_txt article17(2), 7(3) change to article\n",
    "\n",
    "#17(2) get second instance\n",
    "\n",
    "df.loc[df['article_txt'] == 'article7(3)', 'article_txt'] = df['article']\n",
    "df.loc[df['article_txt'] == 'article17(2)', 'article_txt'] = df['article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset based on article_txt\n",
    "df1 = df[df['article_txt'].isin([\"article6(1)(b)\", \"article6(2)\", \"article8(1)\", \"article8(2)\", \"article8(3)\", \"referral\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_txt\n",
       "article6(1)(b)    4837\n",
       "article6(2)        224\n",
       "article8(1)         36\n",
       "article8(2)         70\n",
       "article8(3)         11\n",
       "referral            62\n",
       "Name: case_num, dtype: int64"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no of cases by article\n",
    "df1.groupby('article_txt')['case_num'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article6(1)(b)    4865\n",
       "article6(2)        333\n",
       "article8(1)         37\n",
       "article8(2)         96\n",
       "article8(3)         11\n",
       "referral           100\n",
       "Name: article_txt, dtype: int64"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no of documents by article\n",
    "df1['article_txt'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_7976\\3037691790.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['article_match'] = df1['article_txt'] == df1['article']\n"
     ]
    }
   ],
   "source": [
    "df1['article_match'] = df1['article_txt'] == df1['article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     5355\n",
       "False      87\n",
       "Name: article_match, dtype: int64"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['article_match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "referral          76\n",
       "article6(1)(b)     8\n",
       "article6(2)        2\n",
       "article8(2)        1\n",
       "Name: article_txt, dtype: int64"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1['article_match']==False]['article_txt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>case_num</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>file</th>\n",
       "      <th>id</th>\n",
       "      <th>article_txt</th>\n",
       "      <th>article_62</th>\n",
       "      <th>article_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4907</th>\n",
       "      <td>article6(2)</td>\n",
       "      <td>M.5364</td>\n",
       "      <td>art6.1\\M.5364\\m5364_620_5</td>\n",
       "      <td>\\nEUROPEAN COMMISSION \\nDG Competition \\n \\n ...</td>\n",
       "      <td>en</td>\n",
       "      <td>m5364_620_5</td>\n",
       "      <td>4907</td>\n",
       "      <td>article6(1)(b)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>article6(2)</td>\n",
       "      <td>M.5020</td>\n",
       "      <td>art6.1\\M.5020\\m5020_20080711_20212_en</td>\n",
       "      <td>EN\\nCase No COMP/M.5020 -\\nLESAFFRE / GBI UK\\n...</td>\n",
       "      <td>en</td>\n",
       "      <td>m5020_20080711_20212_en</td>\n",
       "      <td>4922</td>\n",
       "      <td>article6(1)(b)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4928</th>\n",
       "      <td>article6(2)</td>\n",
       "      <td>M.4844</td>\n",
       "      <td>art6.1\\M.4844\\m4844_20071003_20212_en</td>\n",
       "      <td>Case No COMP/M.4844 - FORTIS / ABN AMRO ASSETS...</td>\n",
       "      <td>en</td>\n",
       "      <td>m4844_20071003_20212_en</td>\n",
       "      <td>4928</td>\n",
       "      <td>article6(1)(b)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5144</th>\n",
       "      <td>article6(2)</td>\n",
       "      <td>M.8465</td>\n",
       "      <td>art6.1\\M.8465\\m8465_894_5</td>\n",
       "      <td>\\nEUROPEAN COMMISSION \\nDG Competition \\n \\n ...</td>\n",
       "      <td>en</td>\n",
       "      <td>m8465_894_5</td>\n",
       "      <td>5144</td>\n",
       "      <td>article6(1)(b)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>article6(2)</td>\n",
       "      <td>M.8130</td>\n",
       "      <td>art6.1\\M.8130\\m8130_1247_5</td>\n",
       "      <td>\\nEUROPEAN COMMISSION \\nDG Competition \\n \\n ...</td>\n",
       "      <td>en</td>\n",
       "      <td>m8130_1247_5</td>\n",
       "      <td>5166</td>\n",
       "      <td>article6(1)(b)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>article6(2)</td>\n",
       "      <td>M.7792</td>\n",
       "      <td>art6.1\\M.7792\\m7792_2313_3</td>\n",
       "      <td>EUROPEAN COMMISSION \\nDG Competition \\n \\n \\n ...</td>\n",
       "      <td>en</td>\n",
       "      <td>m7792_2313_3</td>\n",
       "      <td>5196</td>\n",
       "      <td>article6(1)(b)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>article6(2)</td>\n",
       "      <td>M.9677</td>\n",
       "      <td>art6.1\\M.9677\\M_9677_8149323_3017_3</td>\n",
       "      <td>\\n \\nEUROPEAN COMMISSION \\nDG Competition \\n ...</td>\n",
       "      <td>en</td>\n",
       "      <td>M_9677_8149323_3017_3</td>\n",
       "      <td>5215</td>\n",
       "      <td>article6(1)(b)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5457</th>\n",
       "      <td>referral</td>\n",
       "      <td>M.8562</td>\n",
       "      <td>art9.3\\M.8562\\m8562_220_3</td>\n",
       "      <td>\\n \\nEUROPEAN COMMISSION \\nDG Competition \\n ...</td>\n",
       "      <td>en</td>\n",
       "      <td>m8562_220_3</td>\n",
       "      <td>5457</td>\n",
       "      <td>article6(1)(b)</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          article case_num                               filename  \\\n",
       "4907  article6(2)   M.5364              art6.1\\M.5364\\m5364_620_5   \n",
       "4922  article6(2)   M.5020  art6.1\\M.5020\\m5020_20080711_20212_en   \n",
       "4928  article6(2)   M.4844  art6.1\\M.4844\\m4844_20071003_20212_en   \n",
       "5144  article6(2)   M.8465              art6.1\\M.8465\\m8465_894_5   \n",
       "5166  article6(2)   M.8130             art6.1\\M.8130\\m8130_1247_5   \n",
       "5196  article6(2)   M.7792             art6.1\\M.7792\\m7792_2313_3   \n",
       "5215  article6(2)   M.9677    art6.1\\M.9677\\M_9677_8149323_3017_3   \n",
       "5457     referral   M.8562              art9.3\\M.8562\\m8562_220_3   \n",
       "\n",
       "                                                   text lang  \\\n",
       "4907   \\nEUROPEAN COMMISSION \\nDG Competition \\n \\n ...   en   \n",
       "4922  EN\\nCase No COMP/M.5020 -\\nLESAFFRE / GBI UK\\n...   en   \n",
       "4928  Case No COMP/M.4844 - FORTIS / ABN AMRO ASSETS...   en   \n",
       "5144   \\nEUROPEAN COMMISSION \\nDG Competition \\n \\n ...   en   \n",
       "5166   \\nEUROPEAN COMMISSION \\nDG Competition \\n \\n ...   en   \n",
       "5196  EUROPEAN COMMISSION \\nDG Competition \\n \\n \\n ...   en   \n",
       "5215   \\n \\nEUROPEAN COMMISSION \\nDG Competition \\n ...   en   \n",
       "5457   \\n \\nEUROPEAN COMMISSION \\nDG Competition \\n ...   en   \n",
       "\n",
       "                         file    id     article_txt article_62  article_match  \n",
       "4907              m5364_620_5  4907  article6(1)(b)       None          False  \n",
       "4922  m5020_20080711_20212_en  4922  article6(1)(b)       None          False  \n",
       "4928  m4844_20071003_20212_en  4928  article6(1)(b)       None          False  \n",
       "5144              m8465_894_5  5144  article6(1)(b)       None          False  \n",
       "5166             m8130_1247_5  5166  article6(1)(b)       None          False  \n",
       "5196             m7792_2313_3  5196  article6(1)(b)       None          False  \n",
       "5215    M_9677_8149323_3017_3  5215  article6(1)(b)       None          False  \n",
       "5457              m8562_220_3  5457  article6(1)(b)       None          False  "
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[(df1['article_match'] == False) & (df1['article_txt'] == \"article6(1)(b)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[(df1['article_match'] == False) & (df1['article_txt'] == \"article6(1)(b)\") & (df1['article'] == \"article6(2)\"), 'article_txt'] = \"article6(2)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_txt\n",
       "article6(1)(b)    4830\n",
       "article6(2)        226\n",
       "article8(1)         36\n",
       "article8(2)         70\n",
       "article8(3)         11\n",
       "referral            62\n",
       "Name: case_num, dtype: int64"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no of cases by article\n",
    "df1.groupby('article_txt')['case_num'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article6(1)(b)    4858\n",
       "article6(2)        340\n",
       "article8(1)         37\n",
       "article8(2)         96\n",
       "article8(3)         11\n",
       "referral           100\n",
       "Name: article_txt, dtype: int64"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no of documents by article\n",
    "df1['article_txt'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5442 entries, 0 to 5457\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   article        5442 non-null   object\n",
      " 1   case_num       5442 non-null   object\n",
      " 2   filename       5442 non-null   object\n",
      " 3   text           5442 non-null   object\n",
      " 4   lang           5442 non-null   object\n",
      " 5   file           5442 non-null   object\n",
      " 6   id             5442 non-null   int64 \n",
      " 7   article_txt    5442 non-null   object\n",
      " 8   article_62     5442 non-null   object\n",
      " 9   article_match  5442 non-null   bool  \n",
      "dtypes: bool(1), int64(1), object(8)\n",
      "memory usage: 430.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save json file name\n",
    "# date = datetime.date.today().strftime('%Y_%m_%d')\n",
    "\n",
    "# file_name = f\"../../../data/processed/df1_{date}.json\"\n",
    "# if os.path.exists(file_name):\n",
    "#     os.remove(file_name)\n",
    "\n",
    "# # save file as json\n",
    "# df1.to_json(file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract specific sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removal of stopwords, punctuations, numeric characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# nltk.download(\"stopwords\")\n",
    "# from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: retain digits, drop repeating terms based on TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus(texts):\n",
    "    eng_stopwords = set(stopwords.words(\"english\"))\n",
    "    def remove_stops_digits(tokens):\n",
    "        token_list =  [token.lower() for token in tokens if token not in eng_stopwords and token not in punctuation and token.isdigit() == False]\n",
    "        processed_text = ' '.join(token_list)\n",
    "        return processed_text\n",
    "    return [remove_stops_digits(word_tokenize(text)) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_7976\\1554108658.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['text_clean'] = preprocess_corpus(df1['text'])\n"
     ]
    }
   ],
   "source": [
    "df1['text_clean'] = preprocess_corpus(df1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"european commission dg competition case m.9001 kuehne nagel temasek jv only english text available authentic regulation ec no 139/2004 merger procedure article b non-opposition date 24/07/2018 in electronic form eur-lex website document number 32018m9001 european commission brussels,24.7.2018 c final public version to notifying parties subject case m.9001 kuehne nagel/temasek/jv commission decision pursuant article b council regulation ec no 139/2004 article agreement european economic area dear sir madam on june european commission received notification proposed concentration pursuant article merger regulation kuehne nagel management ag `` k+n '' switzerland temasek holdings private limited `` temasek '' singapore acquire within meaning article b merger regulation joint control newly created joint venture `` jv '' singapore way purchase shares.3 the business activities undertakings concerned \\uf02d k+n globally active logistics company main activities sea freight airfreight overland forwarding well contract logistics \\uf02d temasek investment company broad range portfolio investments including financial services telecommunications media real estate life sciences energy transportation \\uf02d jv newly established company identify invest young logistics technology companies focus developing commercializing application technology logistics supply chain services products oj l 29.1.2004 p. 'merger regulation with effect december treaty functioning european union 'tfeu introduced certain changes replacement 'community 'union 'common market 'internal market the terminology tfeu used throughout decision oj l 3.1.1994 p. 'eea agreement publication official journal european union no c 09.07.2018 p. commission européenne dg comp merger registry bruxelles belgique europese commissie dg comp merger registry brussel belgië tel +32 229-91111 fax +32 229-64301 e-mail comp-merger-registry ec.europa.eu after examination notification european commission concluded notified operation falls within scope merger regulation paragraph commission notice simplified procedure treatment certain concentrations council regulation ec no 139/2004.4 for reasons set notice simplified procedure european commission decided oppose notified operation declare compatible internal market eea agreement this decision adopted application article b merger regulation article eea agreement for commission signed johannes laitenberger director-general oj c 14.12.2013 p.\""
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['text_clean'][1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_lemmatize(text):\n",
    "    stemmed = [stemmer.stem(token) for token in word_tokenize(text)]\n",
    "    lemmatized = [lemmatizer.lemmatize(token) for token in stemmed]\n",
    "    processed_text = ' '.join(lemmatized)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_7976\\1935988413.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['text_clean'] = [stem_lemmatize(text) for text in df1['text_clean']]\n"
     ]
    }
   ],
   "source": [
    "df1['text_clean'] = [stem_lemmatize(text) for text in df1['text_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"european commiss dg competit case m.9001 kuehn nagel temasek jv onli english text avail authent regul ec no 139/2004 merger procedur articl b non-opposit date 24/07/2018 in electron form eur-lex websit document number 32018m9001 european commiss brussels,24.7.2018 c final public version to notifi parti subject case m.9001 kuehn nagel/temasek/jv commiss decis pursuant articl b council regul ec no 139/2004 articl agreement european econom area dear sir madam on june european commiss receiv notif propos concentr pursuant articl merger regul kuehn nagel manag ag `` k+n `` switzerland temasek hold privat limit `` temasek `` singapor acquir within mean articl b merger regul joint control newli creat joint ventur `` jv `` singapor way purchas shares.3 the busi activ undertak concern \\uf02d k+n global activ logist compani main activ sea freight airfreight overland forward well contract logist \\uf02d temasek invest compani broad rang portfolio invest includ financi servic telecommun medium real estat life scienc energi transport \\uf02d jv newli establish compani identifi invest young logist technolog compani focu develop commerci applic technolog logist suppli chain servic product oj l 29.1.2004 p. 'merger regul with effect decemb treati function european union 'tfeu introduc certain chang replac 'commun 'union 'common market 'intern market the terminolog tfeu use throughout decis oj l 3.1.1994 p. 'eea agreement public offici journal european union no c 09.07.2018 p. commiss européenn dg comp merger registri bruxel belgiqu europe commissi dg comp merger registri brussel belgië tel +32 229-91111 fax +32 229-64301 e-mail comp-merger-registri ec.europa.eu after examin notif european commiss conclud notifi oper fall within scope merger regul paragraph commiss notic simplifi procedur treatment certain concentr council regul ec no 139/2004.4 for reason set notic simplifi procedur european commiss decid oppos notifi oper declar compat intern market eea agreement thi decis adopt applic articl b merger regul articl eea agreement for commiss sign johann laitenberg director-gener oj c 14.12.2013 p .\""
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['text_clean'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save json file name\n",
    "# date = datetime.date.today().strftime('%Y_%m_%d')\n",
    "\n",
    "# file_name = f\"../../../data/processed/pre-processed_0_{date}.json\"\n",
    "# if os.path.exists(file_name):\n",
    "#     os.remove(file_name)\n",
    "\n",
    "# # save file as json\n",
    "# df1.to_json(file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coreference resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing neuralcoref from source\n",
    "#!git clone https://github.com/huggingface/neuralcoref.git\n",
    "#!cd \"D:\\Desktop\\Thesis\\predicting-merger-decision-outcomes\\src\\python\\notebook\\neuralcoref\"\n",
    "# !pip install -r requirements.txt\n",
    "# !pip install -e .\n",
    "# !pip install spacy\n",
    "# !pip install -U neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neuralcoref'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[687], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mneuralcoref\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'neuralcoref'"
     ]
    }
   ],
   "source": [
    "import neuralcoref\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[688], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39men_core_web_lg\u001b[39;49m\u001b[39m'\u001b[39;49m) \n\u001b[0;32m      2\u001b[0m neuralcoref\u001b[39m.\u001b[39madd_to_pipe(nlp)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\spacy\\__init__.py:30\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mif\u001b[39;00m depr_path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     29\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(Warnings\u001b[39m.\u001b[39mW001\u001b[39m.\u001b[39mformat(path\u001b[39m=\u001b[39mdepr_path), \u001b[39mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m---> 30\u001b[0m \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39mload_model(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\spacy\\util.py:170\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_link(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides)\n\u001b[0;32m    169\u001b[0m \u001b[39mif\u001b[39;00m is_package(name):  \u001b[39m# installed as package\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_package(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides)\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m Path(name)\u001b[39m.\u001b[39mexists():  \u001b[39m# path to model data directory\u001b[39;00m\n\u001b[0;32m    172\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\spacy\\util.py:191\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load a model from an installed package.\"\"\"\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(name)\n\u001b[1;32m--> 191\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mload(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\thesis\\lib\\site-packages\\en_core_web_lg\\__init__.py:12\u001b[0m, in \u001b[0;36mload\u001b[1;34m(**overrides)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_init_py(\u001b[39m__file__\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\spacy\\util.py:239\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[1;34m(init_file, **overrides)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_path\u001b[39m.\u001b[39mexists():\n\u001b[0;32m    238\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE052\u001b[39m.\u001b[39mformat(path\u001b[39m=\u001b[39mpath2str(data_path)))\n\u001b[1;32m--> 239\u001b[0m \u001b[39mreturn\u001b[39;00m load_model_from_path(data_path, meta, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\spacy\\util.py:222\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, **overrides)\u001b[0m\n\u001b[0;32m    220\u001b[0m         component \u001b[39m=\u001b[39m nlp\u001b[39m.\u001b[39mcreate_pipe(factory, config\u001b[39m=\u001b[39mconfig)\n\u001b[0;32m    221\u001b[0m         nlp\u001b[39m.\u001b[39madd_pipe(component, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m--> 222\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\u001b[39m.\u001b[39;49mfrom_disk(model_path, exclude\u001b[39m=\u001b[39;49mdisable)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\spacy\\language.py:974\u001b[0m, in \u001b[0;36mLanguage.from_disk\u001b[1;34m(self, path, exclude, disable)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (path \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mexists() \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude:\n\u001b[0;32m    972\u001b[0m     \u001b[39m# Convert to list here in case exclude is (default) tuple\u001b[39;00m\n\u001b[0;32m    973\u001b[0m     exclude \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(exclude) \u001b[39m+\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 974\u001b[0m util\u001b[39m.\u001b[39;49mfrom_disk(path, deserializers, exclude)\n\u001b[0;32m    975\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path \u001b[39m=\u001b[39m path\n\u001b[0;32m    976\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\spacy\\util.py:690\u001b[0m, in \u001b[0;36mfrom_disk\u001b[1;34m(path, readers, exclude)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mfor\u001b[39;00m key, reader \u001b[39min\u001b[39;00m readers\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    688\u001b[0m     \u001b[39m# Split to support file names like meta.json\u001b[39;00m\n\u001b[0;32m    689\u001b[0m     \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude:\n\u001b[1;32m--> 690\u001b[0m         reader(path \u001b[39m/\u001b[39;49m key)\n\u001b[0;32m    691\u001b[0m \u001b[39mreturn\u001b[39;00m path\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\spacy\\language.py:950\u001b[0m, in \u001b[0;36mLanguage.from_disk.<locals>.deserialize_vocab\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeserialize_vocab\u001b[39m(path):\n\u001b[0;32m    949\u001b[0m     \u001b[39mif\u001b[39;00m path\u001b[39m.\u001b[39mexists():\n\u001b[1;32m--> 950\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvocab\u001b[39m.\u001b[39;49mfrom_disk(path)\n\u001b[0;32m    951\u001b[0m     _fix_pretrained_vectors_name(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\spacy\\vocab.pyx:475\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab.from_disk\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\spacy\\vectors.pyx:432\u001b[0m, in \u001b[0;36mspacy.vectors.Vectors.from_disk\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\spacy\\util.py:690\u001b[0m, in \u001b[0;36mfrom_disk\u001b[1;34m(path, readers, exclude)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mfor\u001b[39;00m key, reader \u001b[39min\u001b[39;00m readers\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    688\u001b[0m     \u001b[39m# Split to support file names like meta.json\u001b[39;00m\n\u001b[0;32m    689\u001b[0m     \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude:\n\u001b[1;32m--> 690\u001b[0m         reader(path \u001b[39m/\u001b[39;49m key)\n\u001b[0;32m    691\u001b[0m \u001b[39mreturn\u001b[39;00m path\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\spacy\\vectors.pyx:425\u001b[0m, in \u001b[0;36mspacy.vectors.Vectors.from_disk.load_vectors\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\thesis\\lib\\site-packages\\numpy\\lib\\npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mopen_memmap(file, mode\u001b[39m=\u001b[39mmmap_mode,\n\u001b[0;32m    430\u001b[0m                                   max_header_size\u001b[39m=\u001b[39mmax_header_size)\n\u001b[0;32m    431\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 432\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(fid, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[0;32m    433\u001b[0m                                  pickle_kwargs\u001b[39m=\u001b[39;49mpickle_kwargs,\n\u001b[0;32m    434\u001b[0m                                  max_header_size\u001b[39m=\u001b[39;49mmax_header_size)\n\u001b[0;32m    435\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    436\u001b[0m     \u001b[39m# Try a pickle\u001b[39;00m\n\u001b[0;32m    437\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\thesis\\lib\\site-packages\\numpy\\lib\\format.py:790\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    788\u001b[0m     \u001b[39mif\u001b[39;00m isfileobj(fp):\n\u001b[0;32m    789\u001b[0m         \u001b[39m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m         array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49mfromfile(fp, dtype\u001b[39m=\u001b[39;49mdtype, count\u001b[39m=\u001b[39;49mcount)\n\u001b[0;32m    791\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    792\u001b[0m         \u001b[39m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[0;32m    793\u001b[0m         \u001b[39m# memory-intensive way.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    801\u001b[0m         \u001b[39m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[0;32m    802\u001b[0m         \u001b[39m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[0;32m    803\u001b[0m         array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mndarray(count, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg') \n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[684], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\spacy\\__init__.py:30\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mif\u001b[39;00m depr_path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     29\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(Warnings\u001b[39m.\u001b[39mW001\u001b[39m.\u001b[39mformat(path\u001b[39m=\u001b[39mdepr_path), \u001b[39mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m---> 30\u001b[0m \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39mload_model(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\spacy\\util.py:175\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(name, \u001b[39m\"\u001b[39m\u001b[39mexists\u001b[39m\u001b[39m\"\u001b[39m):  \u001b[39m# Path or Path-like to model data\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_path(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides)\n\u001b[1;32m--> 175\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coref_res(texts):\n",
    "    doc = nlp(texts)\n",
    "    clean = doc._.coref_resolved\n",
    "    return clean\n",
    "\n",
    "df['text_clean'] = [coref_res(text) for text in df['text_clean']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop based on TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: remove highly repeating words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'language'] = detect(df.at[index, 'text_clean'])\n",
    "\n",
    "df['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['language']==\"en\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8a34a3bb875764d64c764b9cffa891f179e7153a1578da198ecc075e870264c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
