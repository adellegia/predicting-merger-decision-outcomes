{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "import glob, re, os, sys, random\n",
    "\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, strip_numeric, strip_multiple_whitespaces, strip_non_alphanum, stem_text, remove_stopwords\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from string import punctuation\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(r\"../../../data/processed/df_eng_clean_filtered_2023_03_11.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count'] = df['sec_text'].str.split().apply(len)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowercase and Remove non-alphanum, digits, punctuations, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_function = [lambda x: x.lower(), strip_tags, strip_punctuation, strip_non_alphanum, strip_multiple_whitespaces, strip_numeric, remove_stopwords] #stem_text\n",
    "\n",
    "df['text_clean'] = df['sec_text'].apply(lambda x: \" \".join(preprocess_string(str(x), CUSTOM_FILTERS)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatize text, no stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "# stemmer = PorterStemmer()\n",
    "\n",
    "def stem_lemmatize(text):\n",
    "    #stemmed = [stemmer.stem(token) for token in word_tokenize(text)]\n",
    "    lemmatized = [lemmatizer.lemmatize(token) for token in word_tokenize(text)]\n",
    "    processed_text = ' '.join(lemmatized)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = [stem_lemmatize(text) for text in df['text_clean']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get length of text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_text'] = df['text_clean'].str.split().apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 9 \n",
      "max: 138766\n"
     ]
    }
   ],
   "source": [
    "print(\"min:\", min(df['count_text']), \n",
    "    \"\\nmax:\", max(df['count_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simplified        311\n",
       "article6(1)(b)      3\n",
       "article6(2)         1\n",
       "Name: article_new, dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['count_text']<=20].article_new.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_new\n",
       "article6(1)(b)    1284\n",
       "article6(2)        201\n",
       "article8(1)         32\n",
       "article8(2)         57\n",
       "article8(3)          9\n",
       "referral            59\n",
       "simplified        3194\n",
       "Name: case_num, dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no of cases by article_new\n",
    "df.groupby('article_new')['case_num'].nunique().sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phase2\n",
       "0             1485\n",
       "1               98\n",
       "referral        59\n",
       "simplified    3194\n",
       "Name: case_num, dtype: int64"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Phase 1 vs. Phase 2\n",
    "df['phase2'] = np.where((df['article_new'].isin(['article6(1)(b)', 'article6(2)'])), 0, 1)\n",
    "df['phase2'] = np.where((df['article_new'].isin(['referral', 'simplified'])), df['article_new'], df['phase2'])\n",
    "\n",
    "df.groupby('phase2')['case_num'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             5079\n",
       "simplified    3194\n",
       "1              292\n",
       "referral       204\n",
       "Name: phase2, dtype: int64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['phase2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wc\n",
       "0    4548\n",
       "1     257\n",
       "Name: case_num, dtype: int64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['wc'] =\"\"\n",
    "# df['wc'] = np.where((df['article_new'].isin(['article6(2)', 'article8(2)'])), 1, 0)\n",
    "# df.groupby('wc')['case_num'].nunique()\n",
    "# df[(df['wc']==1)]['article_new'].value_counts()\n",
    "# df[(df['wc']==1)].groupby('article_new')['case_num'].nunique() # is there a duplicate by casse_num but different filename?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wc\n",
       "0              1316\n",
       "1               257\n",
       "article8(3)       9\n",
       "referral         59\n",
       "simplified     3194\n",
       "Name: case_num, dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With conditions vs. Without conditions\n",
    "df['wc'] = np.where((df['article_new'].isin(['article6(2)', 'article8(2)'])), 1, 0)\n",
    "df['wc'] = np.where((df['article_new'].isin(['referral', 'simplified', 'article8(3)'])), df['article_new'], df['wc'])\n",
    "\n",
    "df.groupby('wc')['case_num'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              4509\n",
       "simplified     3194\n",
       "1               834\n",
       "referral        204\n",
       "article8(3)      28\n",
       "Name: wc, dtype: int64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['wc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "competition\n",
       "0              266\n",
       "1             1316\n",
       "referral        59\n",
       "simplified    3194\n",
       "Name: case_num, dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Potentially anticompetitive vs. No harm to competition\n",
    "df['competition'] = np.where((df['article_new'].isin(['article6(2)', 'article8(2)', 'article8(3)'])), 0, 1)\n",
    "df['competition'] = np.where((df['article_new'].isin(['referral', 'simplified'])), df['article_new'], df['competition'])\n",
    "\n",
    "df.groupby('competition')['case_num'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1             4509\n",
       "simplified    3194\n",
       "0              862\n",
       "referral       204\n",
       "Name: competition, dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['competition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8769 entries, 0 to 11041\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   year         8769 non-null   int64 \n",
      " 1   article_new  8769 non-null   object\n",
      " 2   case_num     8769 non-null   object\n",
      " 3   file         8769 non-null   object\n",
      " 4   section_fin  8769 non-null   object\n",
      " 5   len_pdf      8769 non-null   int64 \n",
      " 6   sec_text     8769 non-null   object\n",
      " 7   count        8769 non-null   int64 \n",
      " 8   text_clean   8769 non-null   object\n",
      " 9   count_text   8769 non-null   int64 \n",
      " 10  phase2       8769 non-null   object\n",
      " 11  wc           8769 non-null   object\n",
      " 12  competition  8769 non-null   object\n",
      "dtypes: int64(4), object(9)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save json file name\n",
    "date = datetime.date.today().strftime('%Y_%m_%d')\n",
    "\n",
    "file_name = f\"../../../data/processed/pre-processed_{date}.json\"\n",
    "if os.path.exists(file_name):\n",
    "    os.remove(file_name)\n",
    "\n",
    "# save file as json\n",
    "df.to_json(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process with NLTk backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download(\"stopwords\")\n",
    "# from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removal of stopwords, punctuations, numeric characters\n",
    "# def preprocess_corpus(texts):\n",
    "#     eng_stopwords = set(stopwords.words(\"english\"))\n",
    "#     def remove_stops_digits(tokens):\n",
    "#         token_list =  [token.lower() for token in tokens if token not in eng_stopwords and token not in punctuation and token.isdigit() == False]\n",
    "#         processed_text = ' '.join(token_list)\n",
    "#         return processed_text\n",
    "#     return [remove_stops_digits(word_tokenize(text)) for text in texts]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coreference resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(r\"../../../data/processed/pre-processed_2023_03_11.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #installing neuralcoref from source\n",
    "# !git clone https://github.com/huggingface/neuralcoref.git\n",
    "# !cd \"D:\\Desktop\\Thesis\\predicting-merger-decision-outcomes\\src\\python\\notebook\\neuralcoref\"\n",
    "# !pip install -r requirements.txt\n",
    "# !pip install -e .\n",
    "# !pip install spacy\n",
    "# !pip install -U neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en_core_web_lg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def coref_res(texts):\n",
    "#     doc = nlp(texts)\n",
    "#     clean = doc._.coref_resolved\n",
    "#     return clean\n",
    "\n",
    "# df['text_clean'] = [coref_res(text) for text in df['text_clean']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8a34a3bb875764d64c764b9cffa891f179e7153a1578da198ecc075e870264c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
