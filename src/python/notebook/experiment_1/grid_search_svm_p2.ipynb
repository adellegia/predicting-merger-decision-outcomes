{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import glob, re, os, sys, random\n",
    "from random import shuffle\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "# Vector representations and embeddings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import gensim\n",
    "\n",
    "# Modeling - Logistic, XGBOOST, SVM\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, roc_auc_score, auc, roc_curve\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(f'../../../python')\n",
    "\n",
    "from balance_split_data import create_label, balance_unique_id, \\\n",
    "create_balanced_excluded, create_train_test_excluded, group_by_case, create_feature_label\n",
    "\n",
    "from grid_search import gridsearch, fit_best_model_train, evaluate, fit_best_model_test, get_feature_importance_cv\n",
    "\n",
    "from ml_model import train_model_cross_val, train_model_test, \\\n",
    "get_feature_importance, get_feature_importance10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(r\"../../../../data/processed/pre-processed_merged_2023_04_03.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance data and split to train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = \"phase2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total decisions: 1583\n",
      "0    1485\n",
      "1      98\n",
      "Name: label, dtype: int64\n",
      "Balancing...\n",
      "Total decisions: 196\n",
      "Labels distribution: \n",
      " 0    98\n",
      "1    98\n",
      "Name: 0, dtype: int64\n",
      "Training set shape: (157,) (157,)\n",
      "Test set shape: (40,) (40,)\n",
      "Creating df_train 1: 78 0: 79\n",
      "Creating df_test1 1: 20 0: 20\n",
      "Creating df_test concatenated with df_excluded with len: 1386\n",
      "Creating df_test 1: 20 0: 1406\n",
      "Grouping df_train by case_num 1: 78 0: 79\n",
      "Grouping df_test by case_num 1: 20 0: 1406\n",
      "Grouping df_test1 by case_num 1: 20 0: 20\n",
      "Grouping df_excluded by case_num with len: 1386\n"
     ]
    }
   ],
   "source": [
    "df1 = create_label(df, label_name)\n",
    "df_unique = balance_unique_id(df1)\n",
    "df_balanced_unique, df_balanced, df_excluded = create_balanced_excluded(df_unique, df1, random_seed=42)\n",
    "df_train, df_test, df_test1 = create_train_test_excluded(df_balanced, df_balanced_unique, df_excluded, random_state=42)\n",
    "df_train_grouped, df_test_grouped, df_test1_grouped, df_excluded_grouped = group_by_case(df_train, df_test, df_test1, df_excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, X_test1, y_test1, X_test2, y_test2 = create_feature_label(df_train_grouped, df_test_grouped, df_test1_grouped, df_excluded_grouped)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with GridSearch Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = LinearSVC()\n",
    "\n",
    "# Create a pipeline with TfidfVectorizer and Model\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(analyzer='word', max_features=5000, stop_words='english')),\n",
    "    ('clf', model)\n",
    "\n",
    "])\n",
    "\n",
    "# Define the grid of hyperparameters to search over\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': [(1,2),(1,1),(1,3), (2,2),(2,3), (3,3)], # limit to trigrams\n",
    "    #'tfidf__analyzer': ('word', 'char'),\n",
    "    #'tfidf__lowercase': (True, False),\n",
    "    'tfidf__max_df': [0.01, 0.025, 0.05], # (0.01, 1.0), # ignore words that occur as more than x% of corpus\n",
    "    # 'tfidf__min_df': (1, 2, 3), # we need to see a word at least (once, twice, thrice) in a document\n",
    "    'tfidf__use_idf': (False, True), # use inverse document frequency weighting\n",
    "    #'tfidf__sublinear_tf': (False, True),\n",
    "    'tfidf__binary': (False, True), #set term frequency binary (all non-zero terms are set to 1)\n",
    "    'tfidf__norm': ('l1', 'l2'), #norm used to normalize term vectors\n",
    "    # 'tfidf__max_features': (None, 2000, 5000),\n",
    "    #'tfidf__stop_words': (None, 'english'),\n",
    "\n",
    "    # 'clf__solver': ['liblinear', 'lbfgs'],\n",
    "    'clf__C':(0.1, 1, 5) # penalty parameter for the model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "done in 6345.555s\n",
      "Best cross-validation score:  0.9285604375231739\n",
      "Best parameters set:\n",
      "\tclf__C: 0.1\n",
      "\ttfidf__binary: True\n",
      "\ttfidf__max_df: 0.05\n",
      "\ttfidf__ngram_range: (1, 2)\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: False\n"
     ]
    }
   ],
   "source": [
    "grid_search, best_parameters = gridsearch(pipeline, parameters, X_train, y_train, cv=5, scoring='f1') #roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 576 candidates, totalling 1728 fits\n",
      "done in 5034.406s\n",
      "Best cross-validation score:  0.9593286580466068\n",
      "Best parameters set:\n",
      "\tclf__C: 5\n",
      "\ttfidf__binary: True\n",
      "\ttfidf__max_df: 0.05\n",
      "\ttfidf__ngram_range: (1, 2)\n",
      "\ttfidf__norm: 'l1'\n",
      "\ttfidf__use_idf: False\n"
     ]
    }
   ],
   "source": [
    "# grid_search, best_parameters = gridsearch(pipeline, parameters, X_train, y_train, cv=3, scoring='f1') #roc_auc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model fitting and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting the best model\n",
      "Accuracy: 0.9299363057324841\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93        79\n",
      "           1       0.95      0.91      0.93        78\n",
      "\n",
      "    accuracy                           0.93       157\n",
      "   macro avg       0.93      0.93      0.93       157\n",
      "weighted avg       0.93      0.93      0.93       157\n",
      "\n",
      "\n",
      "CR: (0.930650406504065, 0.9298117494320026, 0.9298907968984695, None)\n",
      "\n",
      "Confusion matrix:\n",
      " [[75  4]\n",
      " [ 7 71]] \n",
      "\n",
      "_______________________\n",
      "\n",
      "\n",
      " Accuracy: 92.994 \n",
      " Precision: 0.947 \n",
      " Recall: 0.910 \n",
      " F1: 0.928 \n",
      " FPR: 0.051 \n",
      " ROC_AUC: 0.930\n"
     ]
    }
   ],
   "source": [
    "pipeline_cv, y_predict_cv = fit_best_model_train(X_train, y_train, model, best_parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9299363057324841\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93        79\n",
      "           1       0.95      0.91      0.93        78\n",
      "\n",
      "    accuracy                           0.93       157\n",
      "   macro avg       0.93      0.93      0.93       157\n",
      "weighted avg       0.93      0.93      0.93       157\n",
      "\n",
      "\n",
      "CR: (0.930650406504065, 0.9298117494320026, 0.9298907968984695, None)\n",
      "\n",
      "Confusion matrix:\n",
      " [[75  4]\n",
      " [ 7 71]] \n",
      "\n",
      "_______________________\n",
      "\n",
      "\n",
      " Accuracy: 92.994 \n",
      " Precision: 0.947 \n",
      " Recall: 0.910 \n",
      " F1: 0.928 \n",
      " FPR: 0.051 \n",
      " ROC_AUC: 0.930\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_train, y_predict_cv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the features and coefficients into a dataframe determined by gridsearchCV best_parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>car light</td>\n",
       "      <td>-0.152551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3414</th>\n",
       "      <td>prescription</td>\n",
       "      <td>-0.145527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>commercial vehicle</td>\n",
       "      <td>-0.142814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>currently controlled</td>\n",
       "      <td>-0.132636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>italy united</td>\n",
       "      <td>0.129468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  importance\n",
       "491              car light   -0.152551\n",
       "3414          prescription   -0.145527\n",
       "621     commercial vehicle   -0.142814\n",
       "1002  currently controlled   -0.132636\n",
       "2528          italy united    0.129468"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_cv = get_feature_importance_cv(pipeline_cv)\n",
    "df_features_cv.to_excel('../../../../output/tables/features_svm_cv_full_p2.xlsx', index=True)\n",
    "df_features_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing on test set\n",
      "Accuracy: 0.9417952314165497\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1406\n",
      "           1       0.16      0.75      0.27        20\n",
      "\n",
      "    accuracy                           0.94      1426\n",
      "   macro avg       0.58      0.85      0.62      1426\n",
      "weighted avg       0.98      0.94      0.96      1426\n",
      "\n",
      "\n",
      "CR: (0.5787696924231058, 0.8472617354196301, 0.6175918476803433, None)\n",
      "\n",
      "Confusion matrix:\n",
      " [[1328   78]\n",
      " [   5   15]] \n",
      "\n",
      "_______________________\n",
      "\n",
      "\n",
      " Accuracy: 94.180 \n",
      " Precision: 0.161 \n",
      " Recall: 0.750 \n",
      " F1: 0.265 \n",
      " FPR: 0.055 \n",
      " ROC_AUC: 0.847\n"
     ]
    }
   ],
   "source": [
    "y_predict_cv_test = fit_best_model_test(X_test, y_test, pipeline_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9417952314165497\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1406\n",
      "           1       0.16      0.75      0.27        20\n",
      "\n",
      "    accuracy                           0.94      1426\n",
      "   macro avg       0.58      0.85      0.62      1426\n",
      "weighted avg       0.98      0.94      0.96      1426\n",
      "\n",
      "\n",
      "CR: (0.5787696924231058, 0.8472617354196301, 0.6175918476803433, None)\n",
      "\n",
      "Confusion matrix:\n",
      " [[1328   78]\n",
      " [   5   15]] \n",
      "\n",
      "_______________________\n",
      "\n",
      "\n",
      " Accuracy: 94.180 \n",
      " Precision: 0.161 \n",
      " Recall: 0.750 \n",
      " F1: 0.265 \n",
      " FPR: 0.055 \n",
      " ROC_AUC: 0.847\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_predict_cv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing on test set\n",
      "Accuracy: 0.8\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81        20\n",
      "           1       0.83      0.75      0.79        20\n",
      "\n",
      "    accuracy                           0.80        40\n",
      "   macro avg       0.80      0.80      0.80        40\n",
      "weighted avg       0.80      0.80      0.80        40\n",
      "\n",
      "\n",
      "CR: (0.803030303030303, 0.8, 0.7994987468671679, None)\n",
      "\n",
      "Confusion matrix:\n",
      " [[17  3]\n",
      " [ 5 15]] \n",
      "\n",
      "_______________________\n",
      "\n",
      "\n",
      " Accuracy: 80.000 \n",
      " Precision: 0.833 \n",
      " Recall: 0.750 \n",
      " F1: 0.789 \n",
      " FPR: 0.150 \n",
      " ROC_AUC: 0.800\n"
     ]
    }
   ],
   "source": [
    "y_predict_cv_test1 = fit_best_model_test(X_test1, y_test1, pipeline_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
